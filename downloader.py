"""
Telethon ä¸‹è½½å¼•æ“ (å®Œæ•´ç‰ˆ)
å®ç°å¹¶å‘ä¸‹è½½ã€æ–­ç‚¹ç»­ä¼ ï¼ˆè·¨é‡å¯ï¼‰ã€ä»»åŠ¡ç®¡ç†
"""
import asyncio
import os
import time
import math
import json
from collections import deque
from datetime import datetime
from typing import Optional, Deque, List, Dict
from dataclasses import dataclass, asdict, field
from telethon import TelegramClient, types
from telethon.sessions import StringSession
from config import Config
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    format='%(asctime)s | %(levelname)-7s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    level=Config.LOG_LEVEL,
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(Config.LOG_FILE, encoding='utf-8')
    ]
)
logger = logging.getLogger("TelethonEngine")

# ==================== æ•°æ®ç»“æ„ ====================

@dataclass
class FilePart:
    """æ–‡ä»¶åˆ†ç‰‡ä¿¡æ¯"""
    index: int                # åˆ†ç‰‡åºå·
    start_offset: int         # èµ·å§‹å­—èŠ‚ (åŒ…å«)
    end_offset: int           # ç»“æŸå­—èŠ‚ (åŒ…å«)
    status: str = "pending"   # pending/downloading/completed
    
    @property
    def size(self) -> int:
        return self.end_offset - self.start_offset + 1

@dataclass
class DownloadTask:
    """ä¸‹è½½ä»»åŠ¡æ•°æ®ç»“æ„"""
    message_id: int
    chat_id: int
    file_name: str
    file_size: int
    downloaded_bytes: int = 0
    status: str = "pending"
    parts: List[Dict] = field(default_factory=list) 
    created_at: str = ""
    updated_at: str = ""
    
    # è¿è¡Œæ—¶å¼•ç”¨ (ä¸ä¿å­˜åˆ° JSON)
    message: object = field(default=None, repr=False)
    
    @property
    def progress_percent(self) -> float:
        if self.file_size == 0: return 0.0
        return self.downloaded_bytes * 100 / self.file_size

    def to_dict(self):
        # æ‰‹åŠ¨æ„å»ºå­—å…¸ï¼Œé¿å… asdict æ·±åº¦é€’å½’å¯¼è‡´åºåˆ—åŒ– message å‡ºé”™
        return {
            "message_id": self.message_id,
            "chat_id": self.chat_id,
            "file_name": self.file_name,
            "file_size": self.file_size,
            "downloaded_bytes": self.downloaded_bytes,
            "status": self.status,
            "parts": self.parts,
            "created_at": self.created_at,
            "updated_at": self.updated_at
        }
    
    @classmethod
    def from_dict(cls, data):
        return cls(**data)


# ==================== ä¸‹è½½ç®¡ç†å™¨ ====================

class TelethonDownloader:
    def __init__(self, client: TelegramClient):
        self.client = client
        self.tasks: Deque[DownloadTask] = deque()
        self.current_task: Optional[DownloadTask] = None
        self.is_running = False
        
        # Worker Pool
        self.workers: List[TelegramClient] = []
        self.worker_lock = asyncio.Lock()
        self.worker_queue = asyncio.Queue()
        self._session_str = None  # å»¶è¿Ÿä¿å­˜ Session å­—ç¬¦ä¸²
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        Config.ensure_directories()

    async def _ensure_workers_ready(self):
        """ç¡®ä¿ Worker å®¢æˆ·ç«¯æ± å°±ç»ªï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
        async with self.worker_lock:
            # å¦‚æœé˜Ÿåˆ—ä¸ºç©ºä½†æœ‰ workersï¼Œæ£€æŸ¥è¿æ¥çŠ¶æ€
            if self.workers:
                # æ£€æŸ¥ç¬¬ä¸€ä¸ª worker çš„è¿æ¥çŠ¶æ€
                sample_worker = self.workers[0]
                if not sample_worker.is_connected():
                    logger.info("ğŸ”„ æ£€æµ‹åˆ° Worker è¿æ¥æ–­å¼€ï¼Œæ­£åœ¨é‡æ–°è¿æ¥...")
                    await self._reconnect_all_workers()
                return
            
            # é¦–æ¬¡åˆå§‹åŒ–
            await self._initialize_workers_internal()
    
    async def _initialize_workers_internal(self):
        """å†…éƒ¨åˆå§‹åŒ–æ–¹æ³•"""
        logger.info(f"ğŸ”§ æ­£åœ¨åˆå§‹åŒ– {Config.WORKER_COUNT} ä¸ª Worker å®¢æˆ·ç«¯...")
        
        # å¯¼å‡ºä¸»å®¢æˆ·ç«¯ Session
        self._session_str = StringSession.save(self.client.session)
        
        for i in range(Config.WORKER_COUNT):
            try:
                worker = TelegramClient(
                    StringSession(self._session_str),
                    Config.API_ID,
                    Config.API_HASH,
                    proxy=self.client._proxy,
                    device_model="Desktop",
                    system_version="Windows 10",
                    app_version="4.16.8 x64",
                    lang_code="en"
                )
                await worker.connect()
                self.workers.append(worker)
                self.worker_queue.put_nowait(worker)
                logger.info(f"  âœ… Worker {i+1} å°±ç»ª")
            except Exception as e:
                logger.error(f"  âŒ Worker {i+1} åˆå§‹åŒ–å¤±è´¥: {e}")
        
        logger.info(f"âœ¨ Worker åˆå§‹åŒ–å®Œæˆï¼Œå¯ç”¨: {len(self.workers)}")

    async def _reconnect_all_workers(self):
        """é‡æ–°è¿æ¥æ‰€æœ‰ Worker"""
        # æ¸…ç©ºé˜Ÿåˆ—
        while not self.worker_queue.empty():
            try:
                self.worker_queue.get_nowait()
            except:
                break
        
        # é‡æ–°è¿æ¥æ¯ä¸ª worker
        for i, worker in enumerate(self.workers):
            try:
                if not worker.is_connected():
                    await worker.connect()
                self.worker_queue.put_nowait(worker)
                logger.info(f"  âœ… Worker {i+1} é‡è¿æˆåŠŸ")
            except Exception as e:
                logger.error(f"  âŒ Worker {i+1} é‡è¿å¤±è´¥: {e}")

    async def initialize_workers(self):
        """å…¬å¼€çš„åˆå§‹åŒ–æ–¹æ³•ï¼ˆå…¼å®¹æ—§è°ƒç”¨ï¼Œä½†ç°åœ¨æ˜¯å¯é€‰çš„ï¼‰"""
        # ä¿ç•™æ­¤æ–¹æ³•ä»¥å…¼å®¹ main.py ä¸­çš„è°ƒç”¨ï¼Œä½†å®é™…åˆå§‹åŒ–å»¶è¿Ÿåˆ°é¦–æ¬¡ä½¿ç”¨
        logger.info("ğŸ’¡ Worker å°†åœ¨é¦–æ¬¡ä¸‹è½½æ—¶åˆå§‹åŒ–")
        
    async def add_task(self, message):
        """æ·»åŠ ä¸‹è½½ä»»åŠ¡ (æ”¯æŒæ–­ç‚¹ç»­ä¼ )"""
        task = self._init_or_load_task(message)
        
        # å¦‚æœä»»åŠ¡å·²ç»å®Œæˆï¼ˆä¸”æ–‡ä»¶å®Œæ•´ï¼‰ï¼Œåˆ™è·³è¿‡
        file_path = os.path.join(Config.DOWNLOAD_DIR, task.file_name)
        if task.status == 'completed' and os.path.exists(file_path) and os.path.getsize(file_path) == task.file_size:
            logger.info(f"âœ… æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {task.file_name}")
            return

        # åŠ å…¥é˜Ÿåˆ—
        # é¿å…é˜Ÿåˆ—ä¸­é‡å¤æ·»åŠ 
        for t in self.tasks:
            if t.message_id == task.message_id and t.chat_id == task.chat_id:
                logger.info(f"âš ï¸ ä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­: {task.file_name}")
                return
        
        self.tasks.append(task)
        logger.info(f"â• å·²æ·»åŠ ä»»åŠ¡: {task.file_name} ({task.file_size/1024/1024:.2f} MB) [é˜Ÿåˆ—: {len(self.tasks)}]")
        
        # å¯åŠ¨å¤„ç†
        if not self.is_running:
            asyncio.create_task(self.process_queue())

    def _init_or_load_task(self, message) -> DownloadTask:
        """åŠ è½½æˆ–åˆå§‹åŒ–ä»»åŠ¡"""
        progress_file = Config.get_progress_file_path(message.id, message.chat_id)
        
        # 1. å°è¯•åŠ è½½ç°æœ‰ä»»åŠ¡
        if os.path.exists(progress_file):
            try:
                with open(progress_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    task = DownloadTask.from_dict(data)
                    task.message = message # é‡æ–°å…³è” message å¯¹è±¡
                    logger.info(f"ğŸ”„ æ¢å¤ä»»åŠ¡: {task.file_name} (è¿›åº¦: {task.progress_percent:.1f}%)")
                    return task
            except Exception as e:
                logger.warning(f"âš ï¸ è¿›åº¦æ–‡ä»¶æŸåï¼Œé‡æ–°åˆ›å»º: {e}")
        
        # 2. åˆ›å»ºæ–°ä»»åŠ¡
        # è·å–æ–‡ä»¶å
        file_name = "unknown"
        if message.file:
            file_name = message.file.name or f"file_{message.id}{message.file.ext}"
        
        file_size = message.file.size if message.file else 0
        
        # è®¡ç®—åˆ†ç‰‡
        part_size = Config.PART_SIZE
        num_parts = math.ceil(file_size / part_size) if file_size > 0 else 1
        
        parts = []
        for i in range(num_parts):
            start = i * part_size
            end = min((i + 1) * part_size - 1, file_size - 1) if file_size > 0 else 0
            parts.append(asdict(FilePart(index=i, start_offset=start, end_offset=end)))
            
        task = DownloadTask(
            message_id=message.id,
            chat_id=message.chat_id,
            file_name=file_name,
            file_size=file_size,
            status="pending",
            parts=parts,
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat(),
            message=message
        )
        self._save_task(task)
        return task

    def _save_task(self, task: DownloadTask):
        """ä¿å­˜ä»»åŠ¡è¿›åº¦åˆ° JSON"""
        task.updated_at = datetime.now().isoformat()
        progress_file = Config.get_progress_file_path(task.message_id, task.chat_id)
        
        # è®¡ç®—å·²ä¸‹è½½é‡
        total = 0
        # ç®€å•ä¼°ç®—ï¼šå®Œæˆçš„åˆ†ç‰‡ + æ­£åœ¨ä¸‹è½½åˆ†ç‰‡çš„å·²ä¸‹è½½é‡
        # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œåªç»Ÿè®¡ 'completed' çš„åˆ†ç‰‡ã€‚æ›´ç²¾ç¡®çš„éœ€è¦è¯»å– .part æ–‡ä»¶å¤§å°
        
        try:
            with open(progress_file, 'w', encoding='utf-8') as f:
                json.dump(task.to_dict(), f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜è¿›åº¦å¤±è´¥: {e}")

    async def process_queue(self):
        """å¤„ç†ä»»åŠ¡é˜Ÿåˆ—"""
        if self.is_running: return
        self.is_running = True
        
        while self.tasks:
            self.current_task = self.tasks.popleft()
            task = self.current_task
            
            logger.info(f"\n{'='*50}")
            logger.info(f"ğŸš€ å¼€å§‹ä»»åŠ¡: {task.file_name}")
            logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°: {task.file_size/1024/1024:.2f} MB")
            logger.info(f"{'='*50}")
            
            try:
                # ç¡®ä¿ Worker å°±ç»ª
                await self._ensure_workers_ready()
                
                task.status = "downloading"
                self._save_task(task)
                
                # æœ€ç»ˆæ–‡ä»¶è·¯å¾„
                file_path = os.path.join(Config.DOWNLOAD_DIR, task.file_name)
                
                # 1. æ‰«æåˆ†ç‰‡çŠ¶æ€
                # æ£€æŸ¥å“ªäº›åˆ†ç‰‡è¿˜æ²¡å®Œæˆ
                pending_parts = []
                self.active_parts = {} # Map: part_index -> downloaded
                self.part_status = {}  # Map: part_index -> status
                
                for p_data in task.parts:
                    p = FilePart(**p_data)
                    part_path = f"{file_path}.part{p.index}"
                    
                    # æ£€æŸ¥åˆ†ç‰‡æ–‡ä»¶çœŸå®çŠ¶æ€
                    if p.status == 'completed':
                        # å¦‚æœæ ‡è®°å®Œæˆä½†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé‡ç½®
                        if not os.path.exists(part_path) and not os.path.exists(file_path):
                            p.status = 'pending'
                            
                    if p.status != 'completed':
                        pending_parts.append(p)
                        self.active_parts[p.index] = 0
                        self.part_status[p.index] = 'pending'
                    else:
                        # å·²å®Œæˆçš„åˆ†ç‰‡
                        self.active_parts[p.index] = p.size
                        self.part_status[p.index] = 'completed'
                
                if not pending_parts:
                    logger.info("ğŸ‰ æ‰€æœ‰åˆ†ç‰‡å·²å®Œæˆï¼Œå‡†å¤‡åˆå¹¶...")
                else:
                    logger.info(f"âš¡ éœ€è¦ä¸‹è½½ {len(pending_parts)}/{len(task.parts)} ä¸ªåˆ†ç‰‡")
                    
                    # å¹¶å‘æ§åˆ¶
                    semaphore = asyncio.Semaphore(Config.MAX_WORKERS)
                    download_tasks = []
                    
                    # åˆå§‹åŒ–è¿›åº¦è¿½è¸ª
                    self._total_parts = len(task.parts)
                    self._start_time = time.time()
                    
                    # å¯åŠ¨ç›‘æ§é¢æ¿
                    monitor_stop = asyncio.Event()
                    monitor_task = asyncio.create_task(
                        self.monitor_progress(task, len(task.parts), monitor_stop)
                    )
                    
                    for part in pending_parts:
                        part_path = f"{file_path}.part{part.index}"
                        download_tasks.append(
                            self.download_part_worker(semaphore, task, part, part_path)
                        )
                    
                    # ç­‰å¾…ä¸‹è½½å®Œæˆ
                    await asyncio.gather(*download_tasks)
                    
                    # åœæ­¢ç›‘æ§
                    monitor_stop.set()
                    await asyncio.sleep(0.1)  # è®©ç›‘æ§æœ‰æœºä¼šæœ€ååˆ·æ–°ä¸€æ¬¡
                
                # å†æ¬¡æ£€æŸ¥æ˜¯å¦å…¨éƒ¨å®Œæˆ
                all_done = True
                for p_data in task.parts:
                    if p_data['status'] != 'completed':
                        all_done = False
                        break
                
                if all_done:
                    # åˆå¹¶è¿™ä¸€æ­¥
                    await self.merge_parts(task, file_path)
                else:
                    task.status = "error"
                    logger.error("âŒ éƒ¨åˆ†åˆ†ç‰‡ä¸‹è½½å¤±è´¥")
                    
            except Exception as e:
                task.status = "error"
                logger.error(f"âŒ ä»»åŠ¡å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
            finally:
                self._save_task(task)
                self.current_task = None
                
        self.is_running = False
        logger.info("ğŸ’¤ é˜Ÿåˆ—å·²ç©º")

    async def download_part_worker(self, semaphore, task, part: FilePart, part_path):
        """Worker - ä¸‹è½½å•ä¸ªåˆ†ç‰‡"""
        async with semaphore:
            self.part_status[part.index] = "waiting"
            worker_client = await self.worker_queue.get()
            
            try:
                self.part_status[part.index] = "downloading"
                task.parts[part.index]['status'] = 'downloading'
                # ç§»é™¤ INFO æ—¥å¿—ä»¥é¿å…å¹²æ‰°ç›‘æ§é¢æ¿
                # logger.info(f"â–¶ï¸  Worker å¼€å§‹ä¸‹è½½åˆ†ç‰‡ P{part.index} ({part.size/1024/1024:.1f} MB)")
                
                try:
                    await self.download_part_telethon(worker_client, task.message, part_path, part.index, part.start_offset, part.end_offset)
                    
                    task.parts[part.index]['status'] = 'completed'
                    self.part_status[part.index] = "completed"
                    # ç§»é™¤ INFO æ—¥å¿—ä»¥é¿å…å¹²æ‰°ç›‘æ§é¢æ¿
                    # logger.info(f"âœ… åˆ†ç‰‡ P{part.index} å®Œæˆ")
                    
                except Exception as e:
                    self.part_status[part.index] = "error"
                    task.parts[part.index]['status'] = 'error'
                    logger.error(f"âŒ P{part.index} å¤±è´¥: {e}")
                    raise e
            finally:
                self.worker_queue.put_nowait(worker_client)

    async def download_part_telethon(self, client: TelegramClient, message, part_path, part_index, start_byte, end_byte):
        """åº•å±‚çš„ Telethon åˆ†ç‰‡ä¸‹è½½"""
        current_offset = 0
        expected_size = end_byte - start_byte + 1
        
        # æ–­ç‚¹ç»­ä¼ æ£€æŸ¥
        if os.path.exists(part_path):
            current = os.path.getsize(part_path)
            if current >= expected_size:
                self.active_parts[part_index] = expected_size
                return
            current_offset = current
            self.active_parts[part_index] = current_offset
        
        request_offset = start_byte + current_offset
        bytes_to_download = expected_size - current_offset
        
        if bytes_to_download <= 0: return
        
        mode = 'ab' if current_offset > 0 else 'wb'
        
        with open(part_path, mode) as f:
            async for chunk in client.iter_download(
                message,
                offset=request_offset,
                limit=bytes_to_download,
                chunk_size=512 * 1024, # 512KB
                request_size=512 * 1024,
            ):
                # è®¡ç®—å‰©ä½™éœ€è¦å†™å…¥çš„å­—èŠ‚æ•°ï¼Œé˜²æ­¢æº¢å‡º
                remaining = expected_size - current_offset
                if remaining <= 0:
                    break
                
                # å¦‚æœ chunk è¶…å‡ºå‰©ä½™ç©ºé—´ï¼Œæˆªæ–­
                if len(chunk) > remaining:
                    chunk = chunk[:remaining]
                
                f.write(chunk)
                current_offset += len(chunk)
                
                # æ›´æ–°å®æ—¶è¿›åº¦ (ç”¨äºç›‘æ§é¢æ¿)ï¼Œé™åˆ¶ä¸è¶…è¿‡é¢„æœŸå¤§å°
                self.active_parts[part_index] = min(current_offset, expected_size)

    async def merge_parts(self, task, file_path):
        """åˆå¹¶åˆ†ç‰‡"""
        logger.info(f"\nğŸ”„ æ­£åœ¨åˆå¹¶ {len(task.parts)} ä¸ªåˆ†ç‰‡...")
        
        # ç®€å•æ£€æŸ¥æ‰€æœ‰åˆ†ç‰‡æ˜¯å¦éƒ½åœ¨
        for p in task.parts:
            part_path = f"{file_path}.part{p['index']}"
            if not os.path.exists(part_path):
                logger.error(f"âŒ ç¼ºå¤±åˆ†ç‰‡æ–‡ä»¶: {part_path}")
                return

        with open(file_path, 'wb') as outfile:
            for p in task.parts:
                part_path = f"{file_path}.part{p['index']}"
                with open(part_path, 'rb') as infile:
                    while True:
                        chunk = infile.read(4 * 1024 * 1024) # 4MB Buffer
                        if not chunk: break
                        outfile.write(chunk)
                
                # åˆ é™¤ä¸´æ—¶åˆ†ç‰‡
                try: os.remove(part_path)
                except: pass
        
        task.status = "completed"
        self._save_task(task)
        
        # åˆ é™¤è¿›åº¦æ–‡ä»¶
        try:
            os.remove(Config.get_progress_file_path(task.message_id, task.chat_id))
        except: pass
        
        logger.info(f"âœ… ä¸‹è½½å®Œæˆ: {task.file_name}")
        logger.info(f"ğŸ“‚ {file_path}")

    async def monitor_progress(self, task, num_parts, stop_event):
        """è¿›åº¦ç›‘æ§é¢æ¿ - å®æ—¶åˆ·æ–°æ˜¾ç¤º"""
        total_size = task.file_size
        last_bytes = 0
        last_time = time.time()
        speed = 0
        first_print = True
        
        # é¢„ç•™è¡Œæ•°
        LINES_COUNT = 5
        
        while not stop_event.is_set():
            # ç»Ÿè®¡å„çŠ¶æ€ - ç›´æ¥ä» part_status è¯»å–
            completed = 0
            downloading = 0
            waiting = 0
            pending = 0
            downloading_list = []
            
            for i in range(num_parts):
                status = self.part_status.get(i, 'pending')
                if status == 'completed':
                    completed += 1
                elif status == 'downloading':
                    downloading += 1
                    # è·å–è¯¥åˆ†ç‰‡çš„è¿›åº¦
                    current = self.active_parts.get(i, 0)
                    p_data = task.parts[i]
                    expected = p_data['end_offset'] - p_data['start_offset'] + 1
                    pct = min(100, (current / expected * 100)) if expected > 0 else 0
                    downloading_list.append(f"P{i}:{pct:.0f}%")
                elif status == 'waiting':
                    waiting += 1
                    downloading_list.append(f"P{i}:â³")
                else:
                    pending += 1
            
            # è®¡ç®—è¿›åº¦å’Œé€Ÿåº¦
            total_downloaded = sum(self.active_parts.values())
            now = time.time()
            elapsed = now - last_time
            if elapsed >= 0.5:
                speed = (total_downloaded - last_bytes) / elapsed
                last_bytes = total_downloaded
                last_time = now
            
            percent = min(100, (total_downloaded / total_size * 100)) if total_size > 0 else 0
            
            # è¿›åº¦æ¡
            bar_len = 30
            filled = int(bar_len * percent / 100)
            bar = 'â–ˆ' * filled + 'â–‘' * (bar_len - filled)
            
            # ETA
            eta = "--:--"
            if speed > 0:
                remaining = (total_size - total_downloaded) / speed
                if remaining < 3600:
                    eta = f"{int(remaining//60):02d}:{int(remaining%60):02d}"
                else:
                    eta = f"{int(remaining//3600)}h{int((remaining%3600)//60):02d}m"
            
            # æ´»è·ƒåˆ†ç‰‡ï¼ˆæœ€å¤š6ä¸ªï¼‰
            active_str = ' '.join(downloading_list[:6])
            if len(downloading_list) > 6:
                active_str += '...'
            
            # æ˜¾ç¤ºå†…å®¹
            # ä½¿ç”¨ ANSI è½¬ä¹‰åºåˆ— \033[K æ¸…é™¤å½“å‰è¡Œ
            lines = [
                f"{'â•'*60}",
                f"  [{bar}] {percent:5.1f}%",
                f"  ğŸ“¥ {total_downloaded/1024/1024:.1f}/{total_size/1024/1024:.1f} MB | âš¡ {speed/1024/1024:.2f} MB/s | ETA: {eta}",
                f"  âœ…{completed} â¬‡ï¸{downloading} â³{waiting} ğŸ“‹{pending}  |  {active_str}",
                f"{'â•'*60}"
            ]
            
            # åˆ·æ–°æ˜¾ç¤º
            if not first_print:
                # ç§»åŠ¨å…‰æ ‡ä¸Šç§» N è¡Œ
                print(f"\033[{LINES_COUNT}A", end="", flush=True)
            
            for line in lines:
                # \033[2K æ¸…é™¤æ•´è¡Œ, \r å›åˆ°è¡Œé¦–
                print(f"\033[2K\r{line}", flush=True)
                
            first_print = False
            
            await asyncio.sleep(0.2)

